# LLM Fine-Tuning Project

This repository contains my final project for the **Generative Artificial Intelligence** course.  
The project focuses on fine-tuning the **TinyLlama** language model using a small custom question–answer dataset.

---

## Project Objective

The main objective of this project is to understand how large language models (LLMs) can be adapted to specific tasks using parameter-efficient fine-tuning techniques, especially **LoRA (Low-Rank Adaptation)**.  
Through this project, I explored the full pipeline of dataset preparation, model fine-tuning, and inference.

---

## Dataset

A small custom dataset was created in **instruction–response format**.

Each example follows this structure:
- **Instruction:** A question related to generative AI  
- **Response:** A short and clear answer  

The dataset covers topics such as:
- What is generative AI  
- Differences between generative and discriminative models  
- Applications of generative AI  
- Overfitting and generalization  
- Language models  

---

## Model and Tools

- **Base model:** TinyLlama (1.1B Chat)
- **Fine-tuning method:** LoRA (using PEFT)
- **Environment:** Google Colab (GPU: T4)
- **Libraries used:**
  - PyTorch  
  - Transformers (Hugging Face)  
  - PEFT  
  - Datasets  

---

Open directly in Colab:
https://colab.research.google.com/github/osamahussein/llm-finetuning-project/blob/main/llm_finetuning_project.ipynb


## Notebook

All implementation steps are available in the notebook:

